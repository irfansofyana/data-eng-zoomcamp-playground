Question 1. Google Cloud SDK
Install Google Cloud SDK. What's the version you have?

To get the version, run gcloud --version

answer:
➜ gcloud --version
Google Cloud SDK 369.0.0
bq 2.0.72
core 2022.01.14
gsutil 5.6

Question 2. Terraform
Now install terraform and go to the terraform directory (week_1_basics_n_setup/1_terraform_gcp/terraform)

After that, run

terraform init
terraform plan
terraform apply
Apply the plan and copy the output (after running apply) to the form.

It should be the entire output - from the moment you typed terraform init to the very end.

Answer:
➜ terraform init

Initializing the backend...

Successfully configured the backend "local"! Terraform will automatically
use this backend unless the backend configuration changes.

Initializing provider plugins...
- Finding latest version of hashicorp/google...
- Installing hashicorp/google v4.7.0...
- Installed hashicorp/google v4.7.0 (signed by HashiCorp)

Terraform has created a lock file .terraform.lock.hcl to record the provider
selections it made above. Include this file in your version control repository
so that Terraform can guarantee to make the same selections by default when
you run "terraform init" in the future.

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.

➜ terraform plan
var.project
  Your GCP Project ID

  Enter a value: dtc-de-339114


Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_bigquery_dataset.dataset will be created
  + resource "google_bigquery_dataset" "dataset" {
      + creation_time              = (known after apply)
      + dataset_id                 = "trips_data_all"
      + delete_contents_on_destroy = false
      + etag                       = (known after apply)
      + id                         = (known after apply)
      + last_modified_time         = (known after apply)
      + location                   = "europe-west6"
      + project                    = "dtc-de-339114"
      + self_link                  = (known after apply)

      + access {
          + domain         = (known after apply)
          + group_by_email = (known after apply)
          + role           = (known after apply)
          + special_group  = (known after apply)
          + user_by_email  = (known after apply)

          + view {
              + dataset_id = (known after apply)
              + project_id = (known after apply)
              + table_id   = (known after apply)
            }
        }
    }

  # google_storage_bucket.data-lake-bucket will be created
  + resource "google_storage_bucket" "data-lake-bucket" {
      + force_destroy               = true
      + id                          = (known after apply)
      + location                    = "EUROPE-WEST6"
      + name                        = "dtc_data_lake_dtc-de-339114"
      + project                     = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = true
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type = "Delete"
            }

          + condition {
              + age                   = 30
              + matches_storage_class = []
              + with_state            = (known after apply)
            }
        }

      + versioning {
          + enabled = true
        }
    }

Plan: 2 to add, 0 to change, 0 to destroy.

───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

Note: You didn't use the -out option to save this plan, so Terraform can't guarantee to take exactly these actions if you run "terraform apply" now.

➜ terraform apply -var="project=dtc-de-339114"

Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # google_bigquery_dataset.dataset will be created
  + resource "google_bigquery_dataset" "dataset" {
      + creation_time              = (known after apply)
      + dataset_id                 = "trips_data_all"
      + delete_contents_on_destroy = false
      + etag                       = (known after apply)
      + id                         = (known after apply)
      + last_modified_time         = (known after apply)
      + location                   = "europe-west6"
      + project                    = "dtc-de-339114"
      + self_link                  = (known after apply)

      + access {
          + domain         = (known after apply)
          + group_by_email = (known after apply)
          + role           = (known after apply)
          + special_group  = (known after apply)
          + user_by_email  = (known after apply)

          + view {
              + dataset_id = (known after apply)
              + project_id = (known after apply)
              + table_id   = (known after apply)
            }
        }
    }

  # google_storage_bucket.data-lake-bucket will be created
  + resource "google_storage_bucket" "data-lake-bucket" {
      + force_destroy               = true
      + id                          = (known after apply)
      + location                    = "EUROPE-WEST6"
      + name                        = "dtc_data_lake_dtc-de-339114"
      + project                     = (known after apply)
      + self_link                   = (known after apply)
      + storage_class               = "STANDARD"
      + uniform_bucket_level_access = true
      + url                         = (known after apply)

      + lifecycle_rule {
          + action {
              + type = "Delete"
            }

          + condition {
              + age                   = 30
              + matches_storage_class = []
              + with_state            = (known after apply)
            }
        }

      + versioning {
          + enabled = true
        }
    }

Plan: 2 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

google_bigquery_dataset.dataset: Creating...
google_storage_bucket.data-lake-bucket: Creating...
google_bigquery_dataset.dataset: Creation complete after 4s [id=projects/dtc-de-339114/datasets/trips_data_all]
google_storage_bucket.data-lake-bucket: Creation complete after 5s [id=dtc_data_lake_dtc-de-339114]

	
Question 3. Count records
How many taxi trips were there on January 15?

Consider only trips that started on January 15.

Query Answer:

SELECT COUNT(*)
FROM yellow_taxi_trips
WHERE TO_CHAR(tpep_pickup_datetime, 'YYYY-MM-DD') = '2021-01-15'

Number Answer: 53024


Question 4. Average
Find the largest tip for each day. On which day it was the largest tip in January?

Use the pick up time for your calculations.

(note: it's not a typo, it's "tip", not "trip")

Query Answer:
SELECT *
FROM yellow_taxi_trips
WHERE tip_amount = (
	SELECT MAX(tip_amount)
	FROM yellow_taxi_trips
)

Number answer: 2021-01-20 11:22:05 - 2021-01-20 19:47:56

Question 5
What was the most popular destination for passengers picked up in central park on January 14?

Use the pick up time for your calculations.

Enter the zone name (not id). If the zone name is unknown (missing), write "Unknown"

Query answer:
SELECT *
FROM taxi_zone AS tzz
WHERE tzz.location_id = (
	SELECT do_location_id
	FROM (
		SELECT do_location_id, COUNT(do_location_id) AS cnt
		FROM yellow_taxi_trips AS y
		LEFT JOIN taxi_zone AS tz
		ON y.pu_location_id = tz.location_id
		WHERE 
			TO_CHAR(tpep_pickup_datetime, 'YYYY-MM-DD') = '2021-01-14' AND
			tz.zone = 'Central Park'
		GROUP BY do_location_id
		ORDER BY cnt DESC
		LIMIT 1
	) AS sq
)

string answer = Upper East Side South


Question 6
What's the pickup-dropoff pair with the largest average price for a ride (calculated based on total_amount)?

Enter two zone names separated by a slash

For example:

"Jamaica Bay / Clinton East"

If any of the zone names are unknown (missing), write "Unknown". For example, "Unknown / Clinton East".

Query Answer:
SELECT tz.zone, tzz.zone, AVG(total_amount) AS avg
FROM yellow_taxi_trips AS y
LEFT JOIN taxi_zone AS tz
ON y.pu_location_id = tz.location_id
LEFT JOIN taxi_zone AS tzz
ON y.do_location_id = tzz.location_id
GROUP BY tz.zone, tzz.zone
ORDER BY avg DESC

string answer = Alphabet City / Unknown